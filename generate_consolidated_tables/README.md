# ğŸš€ Cloud Run Job: Crear Tablas Consolidadas

## ğŸ“‹ DescripciÃ³n

Este Cloud Run Job crea **tablas consolidadas optimizadas** en `pph-central.bronze` a partir de las vistas Silver de cada compaÃ±Ã­a.

## ğŸ¯ CaracterÃ­sticas

- âœ… **Particionamiento por MES** (`DATE_TRUNC(created_on, MONTH)`) - Evita lÃ­mite de 4000 particiones
- âœ… **Clusterizado** segÃºn metadatos de `management.metadata_consolidated_tables`
- âœ… **No interactivo** - Procesa todas las tablas automÃ¡ticamente
- âœ… **Timeout de 1 hora** - Suficiente para procesar todas las tablas
- âœ… **8GB RAM + 4 CPUs** - Recursos suficientes para queries grandes

## ğŸ“Š Flujo del Job

```
1. Cargar metadatos (partition_fields, cluster_fields)
   â†“
2. Obtener tablas con vistas Silver disponibles
   â†“
3. Para cada tabla:
   - Obtener compaÃ±Ã­as que tienen la vista
   - Construir UNION ALL de todas las vistas
   - Crear tabla con PARTITION BY y CLUSTER BY
   - Crear Scheduled Query (DESHABILITADO) para refresh cada 6 horas
   â†“
4. Resumen final (Ã©xitos, errores, saltadas)
   â†“
5. Instrucciones para habilitar Scheduled Queries sincronizados
```

## ğŸ”§ ConfiguraciÃ³n

### Proyecto y Datasets

- **Proyecto Central:** `pph-central`
- **Dataset Bronze:** `bronze` (tablas consolidadas)
- **Proyecto Source:** `platform-partners-pro` (metadatos y companies)
- **Dataset Silver:** `silver` (vistas por compaÃ±Ã­a)

### Service Account

```
data-consolidation@pph-central.iam.gserviceaccount.com
```

**Permisos requeridos:**
- âœ… `bigquery.dataViewer` en proyectos de compaÃ±Ã­as (para leer vistas Silver)
- âœ… `bigquery.jobUser` en todos los proyectos
- âœ… `bigquery.dataEditor` en `pph-central` (para crear tablas consolidadas)
- âœ… `bigquery.admin` en `pph-central` (para crear Scheduled Queries en Data Transfer)
- âœ… `iam.serviceAccountTokenCreator` para DTS Service Agent

### Recursos del Job

- **Memoria:** 8 GB
- **CPU:** 4 cores
- **Timeout:** 3600 segundos (1 hora)
- **Max Retries:** 3

## ğŸš€ Despliegue

### Paso 0: Crear Service Account (Solo primera vez)

```bash
# 1. Crear service account en pph-central
gcloud iam service-accounts create data-consolidation \
  --display-name="Data Consolidation Service Account" \
  --project=pph-central

# 2. Otorgar permisos BigQuery Admin en pph-central
gcloud projects add-iam-policy-binding pph-central \
  --member="serviceAccount:data-consolidation@pph-central.iam.gserviceaccount.com" \
  --role="roles/bigquery.admin"

# 3. Otorgar permisos de lectura en proyectos de compaÃ±Ã­as
# OpciÃ³n A: Script automÃ¡tico (recomendado)
chmod +x grant_permissions.sh
./grant_permissions.sh

# OpciÃ³n B: Manual (repetir para cada proyecto: shape-mhs-1, shape-chc-2, etc.)
gcloud projects add-iam-policy-binding shape-mhs-1 \
  --member="serviceAccount:data-consolidation@pph-central.iam.gserviceaccount.com" \
  --role="roles/bigquery.dataViewer"

# 4. Obtener PROJECT_NUMBER de pph-central
gcloud projects describe pph-central --format="value(projectNumber)"

# 5. Permiso para DTS Service Agent (reemplaza PROJECT_NUMBER)
gcloud iam service-accounts add-iam-policy-binding \
  data-consolidation@pph-central.iam.gserviceaccount.com \
  --member="serviceAccount:service-PROJECT_NUMBER@gcp-sa-bigquerydatatransfer.iam.gserviceaccount.com" \
  --role="roles/iam.serviceAccountTokenCreator" \
  --project=pph-central
```

### Paso 1: Build y Deploy

```bash
cd bq_management/consolidated_central_project_data/generate_consolidated_tables
chmod +x build_deploy.sh
./build_deploy.sh
```

Este script:
1. Crea imagen Docker con `generate_consolidated_tables.py`
2. Sube la imagen a `gcr.io/pph-central/create-consolidated-tables-job`
3. Crea/actualiza el Cloud Run Job con la nueva Service Account

### Paso 2: Ejecutar el Job

```bash
gcloud run jobs execute create-consolidated-tables-job \
  --region=us-east1 \
  --project=pph-central
```

### Paso 3: Monitorear Logs

```bash
# Ver logs en tiempo real
gcloud run jobs logs create-consolidated-tables-job \
  --region=us-east1 \
  --project=pph-central

# Ver logs en Cloud Console
# https://console.cloud.google.com/run/jobs/details/us-east1/create-consolidated-tables-job
```

## ğŸ“Š Estructura de Tablas Consolidadas

### Naming Convention

```
pph-central.bronze.consolidated_{table_name}
```

Ejemplos:
- `consolidated_appointment`
- `consolidated_customer`
- `consolidated_invoice`

### Schema

Todas las tablas consolidadas tienen estos campos adicionales:

```sql
company_project_id STRING   -- Proyecto de la compaÃ±Ã­a (ej: "shape-mhs-1")
company_id INT64            -- ID de la compaÃ±Ã­a (ej: 1)
... [campos originales de la tabla] ...
```

### Particionamiento

```sql
PARTITION BY DATE_TRUNC(created_on, MONTH)
```

**Â¿Por quÃ© MES y no DÃA?**
- LÃ­mite de BigQuery: 4000 particiones mÃ¡ximo
- Por dÃ­a: 4000 dÃ­as = ~11 aÃ±os
- Por mes: 4000 meses = ~333 aÃ±os âœ…

### Clusterizado

SegÃºn metadatos en `management.metadata_consolidated_tables`:

```sql
CLUSTER BY company_id, [otros campos segÃºn tabla]
```

**Beneficios:**
- âœ… Queries mÃ¡s rÃ¡pidos al filtrar por compaÃ±Ã­a
- âœ… Menor costo de queries
- âœ… Mejor organizaciÃ³n de datos

## ğŸ” ValidaciÃ³n

### Verificar que las tablas se crearon

```sql
SELECT 
  table_name,
  row_count,
  size_bytes,
  ROUND(size_bytes / POW(1024, 3), 2) as size_gb,
  creation_time
FROM `pph-central.bronze.__TABLES__`
WHERE table_id LIKE 'consolidated_%'
ORDER BY creation_time DESC;
```

### Ver distribuciÃ³n de datos por compaÃ±Ã­a

```sql
SELECT 
  company_project_id,
  company_id,
  COUNT(*) as total_records
FROM `pph-central.bronze.consolidated_appointment`
GROUP BY company_project_id, company_id
ORDER BY total_records DESC;
```

### Verificar particionamiento

```sql
SELECT 
  partition_id,
  total_rows,
  ROUND(total_logical_bytes / POW(1024, 3), 2) as size_gb
FROM `pph-central.bronze.INFORMATION_SCHEMA.PARTITIONS`
WHERE table_name = 'consolidated_appointment'
ORDER BY partition_id DESC
LIMIT 10;
```

## âš ï¸ Troubleshooting

### Error: Too many partitions

**Problema:** MÃ¡s de 4000 dÃ­as de datos

**SoluciÃ³n:** El Job ya usa `DATE_TRUNC(created_on, MONTH)`. Si aÃºn falla:
1. Cambiar a `DATE_TRUNC(created_on, YEAR)`
2. O filtrar datos histÃ³ricos

### Error: Timeout

**Problema:** El Job no termina en 1 hora

**SoluciÃ³n:**
1. Aumentar `--task-timeout` a 7200 (2 horas)
2. O procesar tablas en lotes

### Error: Out of Memory

**Problema:** Query muy grande para 8GB

**SoluciÃ³n:**
1. Aumentar `--memory` a 16Gi
2. Reducir nÃºmero de compaÃ±Ã­as por lote

### Error: Permission Denied

**Problema:** Service Account sin permisos

**SoluciÃ³n:**
```bash
# Para cada proyecto de compaÃ±Ã­a
gcloud projects add-iam-policy-binding COMPANY_PROJECT_ID \
  --member="serviceAccount:data-analytics@platform-partners-pro.iam.gserviceaccount.com" \
  --role="roles/bigquery.dataViewer"
```

## ğŸ“ Logs de Ejemplo

### Ã‰xito

```
ğŸš€ CLOUD RUN JOB - CREAR TABLAS CONSOLIDADAS
================================================================================
âœ… Metadatos cargados: 24 tablas
âœ… Tablas disponibles: 24

[1/24] appointment
  ğŸ”„ Creando tabla: consolidated_appointment
     ğŸ“Š CompaÃ±Ã­as: 30
     âš™ï¸  Particionado: created_on (por MES)
     ğŸ”— Clusterizado: ['company_id']
  âœ… Tabla creada exitosamente

...

================================================================================
ğŸ¯ RESUMEN FINAL
================================================================================
âœ… Tablas creadas exitosamente: 24
âŒ Tablas con errores: 0
â­ï¸  Tablas saltadas: 0
ğŸ“Š Total procesadas: 24
```

### Con Errores

```
[5/24] customer
  ğŸ”„ Creando tabla: consolidated_customer
     ğŸ“Š CompaÃ±Ã­as: 28
  âŒ Error: Column 'email' type mismatch...

================================================================================
ğŸ¯ RESUMEN FINAL
================================================================================
âœ… Tablas creadas exitosamente: 23
âŒ Tablas con errores: 1
â­ï¸  Tablas saltadas: 0
ğŸ“Š Total procesadas: 24
âš ï¸  Algunas tablas tuvieron errores. Revisa los logs arriba.
```

## ğŸ”„ Re-ejecuciÃ³n

El Job usa `CREATE OR REPLACE TABLE`, por lo que:
- âœ… Es seguro re-ejecutar
- âœ… Sobrescribe tablas existentes
- âœ… No duplica datos
- âš ï¸ Destruye datos antiguos (si cambiaste la lÃ³gica)

## ğŸ“… Mantenimiento

### Actualizar el Job

```bash
# 1. Modificar consolidated_tables_job.py
# 2. Re-deployar
./build_deploy_consolidated.sh
```

### Eliminar el Job

```bash
gcloud run jobs delete create-consolidated-tables-job \
  --region=us-east1 \
  --project=pph-central
```

### Ver historial de ejecuciones

```bash
gcloud run jobs executions list \
  --job=create-consolidated-tables-job \
  --region=us-east1 \
  --project=pph-central
```

## â° Scheduled Queries - Refresh AutomÃ¡tico

El Job crea **Scheduled Queries deshabilitados** para mantener sincronizaciÃ³n perfecta.

### ğŸ“‹ CaracterÃ­sticas:

- **Prefijo:** `sq_consolidated_*` (ej: `sq_consolidated_appointment`)
- **Frecuencia:** Cada 6 horas (aligned con Fivetran)
- **Estado inicial:** PAUSADO (disabled)
- **Estrategia:** `DELETE + INSERT` con filtro de fecha para eficiencia

### âœ… Habilitar Scheduled Queries (Post-Job)

**OpciÃ³n 1: Script Python (Recomendado)**

```bash
cd bq_management/consolidated_central_project_data
python generate_consolidated_tables/enable_all_schedules.py
```

Este script habilitarÃ¡ **todos** los schedules a la vez, garantizando sincronizaciÃ³n perfecta.

**OpciÃ³n 2: Manual en BigQuery Console**

1. Ve a **BigQuery Console â†’ Data Transfers**
2. Filtra por `sq_consolidated_`
3. Habilita cada uno manualmente (uno por uno)

### ğŸ”„ SincronizaciÃ³n con Fivetran

- **Fivetran:** Corre cada 6 horas (12:00 AM, 6:00 AM, 12:00 PM, 6:00 PM UTC)
- **Scheduled Queries:** Empiezan 1 hora despuÃ©s cuando los habilites
- **Ejemplo:** Si habilitas a las 7:00 AM UTC, prÃ³xima ejecuciÃ³n: 1:00 PM UTC

### ğŸ› ï¸ GestiÃ³n de Schedules

**Ver todos los schedules:**
```bash
bq ls --transfer_config --transfer_location=us --project_id=pph-central
```

**Deshabilitar un schedule especÃ­fico:**
```bash
bq update --transfer_config \
  --display_name=sq_consolidated_appointment \
  --disabled \
  --project_id=pph-central
```

## ğŸ¯ PrÃ³ximos Pasos

DespuÃ©s de crear las tablas consolidadas en Bronze:

1. **Paso 3.1:** âœ… Habilitar Scheduled Queries para refresh automÃ¡tico
2. **Paso 4:** Crear vistas consolidadas en `pph-central.silver`
3. **Paso 5:** Configurar permisos para usuarios finales
4. **Paso 6:** Crear dashboards en Looker/Tableau

---

**Fecha de creaciÃ³n:** 2025-10-08  
**VersiÃ³n:** 2.0  
**Autor:** Data Engineering Team

