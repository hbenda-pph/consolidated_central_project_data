{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìä Creaci√≥n de Tablas Consolidadas - pph-central.bronze\n",
        "\n",
        "## Objetivo\n",
        "Crear tablas consolidadas optimizadas en `pph-central.bronze` usando las vistas Silver de cada compa√±√≠a.\n",
        "\n",
        "## Flujo\n",
        "1. **An√°lisis** - Ver qu√© tablas tienen vistas Silver disponibles\n",
        "2. **Metadatos** - Revisar configuraci√≥n de particionado/clusterizado  \n",
        "3. **Prueba** - Crear una tabla consolidada como ejemplo\n",
        "4. **Validaci√≥n** - Verificar estructura y datos\n",
        "5. **Escalado** - Crear todas las tablas restantes\n",
        "\n",
        "## Ventajas del Notebook\n",
        "‚úÖ Sin timeouts de Cloud Shell  \n",
        "‚úÖ Ejecuci√≥n query por query  \n",
        "‚úÖ Visualizaci√≥n inmediata de resultados  \n",
        "‚úÖ Debugging f√°cil  \n",
        "‚úÖ Reutilizable para futuras ejecuciones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# üìã CONFIGURACI√ìN Y SETUP CON AUTENTICACI√ìN\n",
        "import pandas as pd\n",
        "from google.cloud import bigquery\n",
        "from google.auth import default\n",
        "import os\n",
        "\n",
        "# Configuraci√≥n\n",
        "PROJECT_CENTRAL = 'pph-central'\n",
        "PROJECT_SOURCE = 'platform-partners-pro'\n",
        "DATASET_BRONZE = 'bronze'\n",
        "DATASET_SILVER = 'silver'\n",
        "DATASET_SETTINGS = 'settings'\n",
        "DATASET_MANAGEMENT = 'management'\n",
        "\n",
        "# üîê AUTENTICACI√ìN EXPL√çCITA\n",
        "try:\n",
        "    # Intentar autenticaci√≥n por defecto\n",
        "    credentials, project = default()\n",
        "    \n",
        "    # Crear cliente con autenticaci√≥n expl√≠cita\n",
        "    client = bigquery.Client(project=PROJECT_CENTRAL, credentials=credentials)\n",
        "    \n",
        "    print(\"üîê AUTENTICACI√ìN:\")\n",
        "    print(f\"   ‚úÖ Credenciales obtenidas correctamente\")\n",
        "    print(f\"   üìß Usuario: {credentials.service_account_email if hasattr(credentials, 'service_account_email') else 'Usuario actual'}\")\n",
        "    print(f\"   üéØ Proyecto activo: {PROJECT_CENTRAL}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error de autenticaci√≥n: {str(e)}\")\n",
        "    print(\"üí° Soluci√≥n: Ejecuta 'gcloud auth login' en Cloud Shell antes de abrir el notebook\")\n",
        "    client = None\n",
        "\n",
        "print(\"\\nüîß CONFIGURACI√ìN:\")\n",
        "print(f\"   Proyecto Central: {PROJECT_CENTRAL}\")\n",
        "print(f\"   Proyecto Source: {PROJECT_SOURCE}\")\n",
        "print(f\"   Dataset Bronze: {DATASET_BRONZE}\")\n",
        "print(f\"   Dataset Silver: {DATASET_SILVER}\")\n",
        "print(f\"   Dataset Settings: {DATASET_SETTINGS}\")\n",
        "print(f\"   Dataset Management: {DATASET_MANAGEMENT}\")\n",
        "\n",
        "if client:\n",
        "    print(\"\\n‚úÖ Setup completado - Cliente BigQuery inicializado con autenticaci√≥n\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Setup fallido - Problema de autenticaci√≥n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç PASO 1: An√°lisis de Tablas Disponibles\n",
        "\n",
        "Verificamos qu√© tablas tienen vistas Silver exitosas y cu√°ntas compa√±√≠as est√°n disponibles para cada una.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# üìä AN√ÅLISIS: Tablas con Vistas Silver Disponibles\n",
        "query_analysis = f\"\"\"\n",
        "SELECT \n",
        "  table_name,\n",
        "  COUNT(*) as companies_with_silver_views,\n",
        "  STRING_AGG(CAST(company_id AS STRING), ', ' ORDER BY company_id) as company_ids,\n",
        "  STRING_AGG(company_name, ', ' ORDER BY company_id) as company_names\n",
        "FROM (\n",
        "  SELECT DISTINCT\n",
        "    cc.table_name,\n",
        "    cc.company_id,\n",
        "    c.company_name\n",
        "  FROM `{PROJECT_SOURCE}.{DATASET_SETTINGS}.companies_consolidated` cc\n",
        "  JOIN `{PROJECT_SOURCE}.{DATASET_SETTINGS}.companies` c\n",
        "    ON cc.company_id = c.company_id\n",
        "  WHERE cc.consolidated_status = 1  -- Solo vistas Silver exitosas\n",
        "    AND c.company_fivetran_status = TRUE\n",
        "    AND c.company_bigquery_status = TRUE\n",
        ")\n",
        "GROUP BY table_name\n",
        "ORDER BY companies_with_silver_views DESC, table_name\n",
        "\"\"\"\n",
        "\n",
        "# Ejecutar query y mostrar resultados\n",
        "try:\n",
        "    df_analysis = client.query(query_analysis).to_dataframe()\n",
        "    print(\"üìä TABLAS CON VISTAS SILVER DISPONIBLES:\")\n",
        "    print(\"=\" * 80)\n",
        "    print(df_analysis.to_string(index=False))\n",
        "    \n",
        "    # Guardar para uso posterior\n",
        "    available_tables = df_analysis['table_name'].tolist()\n",
        "    print(f\"\\nüìã Total de tablas disponibles: {len(available_tables)}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error en an√°lisis: {str(e)}\")\n",
        "    available_tables = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è PASO 2: Configuraci√≥n de Metadatos\n",
        "\n",
        "Revisamos la configuraci√≥n de particionado y clusterizado para cada tabla.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# üìã METADATOS: Configuraci√≥n de Particionado y Clusterizado\n",
        "query_metadata = f\"\"\"\n",
        "SELECT \n",
        "  table_name,\n",
        "  partition_fields,\n",
        "  cluster_fields,\n",
        "  update_strategy,\n",
        "  created_at,\n",
        "  updated_at\n",
        "FROM `{PROJECT_CENTRAL}.{DATASET_MANAGEMENT}.metadata_consolidated_tables`\n",
        "ORDER BY table_name\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    df_metadata = client.query(query_metadata).to_dataframe()\n",
        "    print(\"‚öôÔ∏è CONFIGURACI√ìN DE METADATOS:\")\n",
        "    print(\"=\" * 100)\n",
        "    print(df_metadata.to_string(index=False))\n",
        "    \n",
        "    # Crear diccionario para acceso r√°pido\n",
        "    metadata_dict = {}\n",
        "    for _, row in df_metadata.iterrows():\n",
        "        metadata_dict[row['table_name']] = {\n",
        "            'partition_fields': row['partition_fields'],\n",
        "            'cluster_fields': row['cluster_fields'],\n",
        "            'update_strategy': row['update_strategy']\n",
        "        }\n",
        "    \n",
        "    print(f\"\\nüìã Metadatos cargados para {len(metadata_dict)} tablas\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error cargando metadatos: {str(e)}\")\n",
        "    metadata_dict = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ PASO 3: Prueba con Tabla Individual\n",
        "\n",
        "Vamos a crear una tabla consolidada como ejemplo. Usaremos `appointment` que suele tener muchas compa√±√≠as disponibles.\n",
        "\n",
        "**Nota:** Cambia `appointment` por la tabla que quieras probar seg√∫n los resultados del an√°lisis anterior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß REGLAS DE NORMALIZACI√ìN ID√âNTICAS AL SCRIPT generate_silver_views.py\n",
        "def generate_cast_for_field(field_name, source_type, target_type):\n",
        "    \"\"\"\n",
        "    Genera la expresi√≥n CAST apropiada para un campo\n",
        "    ID√âNTICA a la funci√≥n en generate_silver_views.py\n",
        "    \"\"\"\n",
        "    if source_type == target_type:\n",
        "        return field_name\n",
        "    \n",
        "    # Mapeo de conversiones seguras - ID√âNTICO AL SCRIPT\n",
        "    safe_casts = {\n",
        "        ('INT64', 'STRING'): f\"CAST({field_name} AS STRING)\",\n",
        "        ('INT64', 'FLOAT64'): f\"CAST({field_name} AS FLOAT64)\",\n",
        "        ('FLOAT64', 'STRING'): f\"CAST({field_name} AS STRING)\",\n",
        "        # üö® CORREGIDO: STRING a INT64/FLOAT64 NO es seguro si contiene letras\n",
        "        ('STRING', 'INT64'): f\"CAST({field_name} AS STRING)\",  # Mantener como STRING\n",
        "        ('STRING', 'FLOAT64'): f\"CAST({field_name} AS STRING)\",  # Mantener como STRING\n",
        "        ('STRING', 'BOOL'): f\"SAFE_CAST({field_name} AS BOOL)\",\n",
        "        ('BOOL', 'STRING'): f\"CAST({field_name} AS STRING)\",\n",
        "        ('DATE', 'STRING'): f\"CAST({field_name} AS STRING)\",\n",
        "        ('DATETIME', 'STRING'): f\"CAST({field_name} AS STRING)\",\n",
        "        ('TIMESTAMP', 'STRING'): f\"CAST({field_name} AS STRING)\",\n",
        "        # üö® CR√çTICO: TIMESTAMP vs INT64 - ID√âNTICO AL SCRIPT\n",
        "        ('INT64', 'TIMESTAMP'): f\"TIMESTAMP_SECONDS({field_name})\",\n",
        "        ('TIMESTAMP', 'INT64'): f\"UNIX_SECONDS({field_name})\",\n",
        "        # JSON a otros tipos - ID√âNTICO AL SCRIPT\n",
        "        ('JSON', 'STRING'): f\"COALESCE(TO_JSON_STRING({field_name}), '')\",\n",
        "        ('JSON', 'INT64'): f\"COALESCE(TO_JSON_STRING({field_name}), '')\",  # A STRING\n",
        "        ('JSON', 'FLOAT64'): f\"COALESCE(TO_JSON_STRING({field_name}), '')\"  # A STRING\n",
        "    }\n",
        "    \n",
        "    cast_key = (source_type, target_type)\n",
        "    if cast_key in safe_casts:\n",
        "        return safe_casts[cast_key]\n",
        "    \n",
        "    # Para conversiones no seguras, usar SAFE_CAST con valor por defecto - ID√âNTICO AL SCRIPT\n",
        "    defaults = {\n",
        "        'STRING': \"''\",\n",
        "        'INT64': '0',\n",
        "        'FLOAT64': '0.0',\n",
        "        'BOOL': 'FALSE',\n",
        "        'DATE': 'NULL',\n",
        "        'DATETIME': 'NULL',\n",
        "        'TIMESTAMP': 'NULL',\n",
        "        'JSON': 'NULL',\n",
        "        'BYTES': 'NULL'\n",
        "    }\n",
        "    default_value = defaults.get(target_type, 'NULL')\n",
        "    \n",
        "    return f\"COALESCE(SAFE_CAST({field_name} AS {target_type}), {default_value})\"\n",
        "\n",
        "# üîç FUNCI√ìN: Obtener estructura de vista Silver de una compa√±√≠a espec√≠fica\n",
        "def get_silver_view_structure(project_id, table_name):\n",
        "    \"\"\"Obtiene la estructura de una vista Silver espec√≠fica\"\"\"\n",
        "    try:\n",
        "        query = f\"\"\"\n",
        "        SELECT \n",
        "          column_name,\n",
        "          ordinal_position,\n",
        "          data_type,\n",
        "          is_nullable\n",
        "        FROM `{project_id}.{DATASET_SILVER}.INFORMATION_SCHEMA.COLUMNS`\n",
        "        WHERE table_name = 'vw_{table_name}'\n",
        "        ORDER BY ordinal_position\n",
        "        \"\"\"\n",
        "        \n",
        "        df_structure = client.query(query).to_dataframe()\n",
        "        return df_structure\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error obteniendo estructura de {project_id}.{DATASET_SILVER}.vw_{table_name}: {str(e)}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "print(\"‚úÖ Reglas de normalizaci√≥n sincronizadas con generate_silver_views.py\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö†Ô∏è IMPORTANTE: Particionamiento por MES\n",
        "\n",
        "**Cambio aplicado:** Las tablas se particionan por **MES** (`DATE_TRUNC(created_on, MONTH)`) en lugar de d√≠a.\n",
        "\n",
        "**Raz√≥n:** BigQuery tiene un l√≠mite de 4000 particiones por tabla. Con particionamiento por d√≠a:\n",
        "- 4000 d√≠as = ~11 a√±os de datos\n",
        "- Si tienes datos hist√≥ricos m√°s antiguos ‚Üí Error\n",
        "\n",
        "**Con particionamiento por MES:**\n",
        "- 4000 meses = ~333 a√±os de datos ‚úÖ\n",
        "- Reduce particiones significativamente\n",
        "- Mejor rendimiento para consultas mensuales/anuales\n",
        "\n",
        "**Si necesitas particionamiento por d√≠a:**\n",
        "1. Filtra datos hist√≥ricos (ej: √∫ltimos 5 a√±os)\n",
        "2. O usa particionamiento por YEAR para datos hist√≥ricos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# üîç FUNCI√ìN: Obtener Compa√±√≠as para una Tabla Espec√≠fica\n",
        "def get_companies_for_table(table_name):\n",
        "    \"\"\"Obtiene las compa√±√≠as disponibles para una tabla espec√≠fica\"\"\"\n",
        "    query = f\"\"\"\n",
        "    SELECT \n",
        "      c.company_id,\n",
        "      c.company_name,\n",
        "      c.company_project_id\n",
        "    FROM `{PROJECT_SOURCE}.{DATASET_SETTINGS}.companies_consolidated` cc\n",
        "    JOIN `{PROJECT_SOURCE}.{DATASET_SETTINGS}.companies` c\n",
        "      ON cc.company_id = c.company_id\n",
        "    WHERE cc.table_name = '{table_name}'\n",
        "      AND cc.consolidated_status = 1  -- Solo vistas Silver exitosas\n",
        "      AND c.company_fivetran_status = TRUE\n",
        "      AND c.company_bigquery_status = TRUE\n",
        "    ORDER BY c.company_id\n",
        "    \"\"\"\n",
        "    \n",
        "    try:\n",
        "        df_companies = client.query(query).to_dataframe()\n",
        "        return df_companies\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error obteniendo compa√±√≠as para {table_name}: {str(e)}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# üß™ PRUEBA: Ver Compa√±√≠as para appointment (o cambiar por otra tabla)\n",
        "test_table = 'appointment'  # Cambiar por la tabla que quieras probar\n",
        "print(f\"üîç COMPA√ë√çAS DISPONIBLES PARA: {test_table}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "df_companies = get_companies_for_table(test_table)\n",
        "if not df_companies.empty:\n",
        "    print(df_companies.to_string(index=False))\n",
        "    print(f\"\\nüìã Total de compa√±√≠as: {len(df_companies)}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  No hay compa√±√≠as disponibles para {test_table}\")\n",
        "    print(\"üí° Prueba con otra tabla de la lista anterior\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# üèóÔ∏è FUNCI√ìN: Crear Tabla Consolidada\n",
        "def create_consolidated_table(table_name, companies_df):\n",
        "    \"\"\"Crea una tabla consolidada para una tabla espec√≠fica\"\"\"\n",
        "    \n",
        "    if companies_df.empty:\n",
        "        print(f\"‚ùå No hay compa√±√≠as disponibles para {table_name}\")\n",
        "        return False\n",
        "    \n",
        "    # Obtener metadatos\n",
        "    if table_name in metadata_dict:\n",
        "        metadata = metadata_dict[table_name]\n",
        "        partition_field = metadata['partition_fields'][0]\n",
        "        cluster_fields = metadata['cluster_fields']\n",
        "    else:\n",
        "        # Valores por defecto\n",
        "        partition_field = 'created_on'\n",
        "        cluster_fields = ['company_id']\n",
        "    \n",
        "    # Construir UNION ALL parts\n",
        "    union_parts = []\n",
        "    for _, company in companies_df.iterrows():\n",
        "        union_part = f\"\"\"\n",
        "        SELECT \n",
        "          '{company['company_project_id']}' AS company_project_id,\n",
        "          {company['company_id']} AS company_id,\n",
        "          *\n",
        "        FROM `{company['company_project_id']}.{DATASET_SILVER}.vw_{table_name}`\"\"\"\n",
        "        union_parts.append(union_part)\n",
        "    \n",
        "    # Configurar clusterizado\n",
        "    cluster_sql = f\"CLUSTER BY {', '.join(cluster_fields)}\" if cluster_fields else \"\"\n",
        "    \n",
        "    # CR√çTICO: Usar MONTH para evitar l√≠mite de 4000 particiones\n",
        "    # Si tienes m√°s de 11 a√±os de datos, cambia a YEAR\n",
        "    # SQL completo\n",
        "    create_sql = f\"\"\"\n",
        "    CREATE OR REPLACE TABLE `{PROJECT_CENTRAL}.{DATASET_BRONZE}.consolidated_{table_name}`\n",
        "    PARTITION BY DATE_TRUNC({partition_field}, MONTH)\n",
        "    {cluster_sql}\n",
        "    AS\n",
        "    {' UNION ALL '.join(union_parts)}\n",
        "    \"\"\"\n",
        "    \n",
        "    print(f\"üîÑ Creando tabla consolidada: consolidated_{table_name}\")\n",
        "    print(f\"üìä Compa√±√≠as: {len(companies_df)}\")\n",
        "    print(f\"‚öôÔ∏è Particionado: {partition_field}\")\n",
        "    print(f\"üîó Clusterizado: {cluster_fields}\")\n",
        "    \n",
        "    try:\n",
        "        query_job = client.query(create_sql)\n",
        "        query_job.result()\n",
        "        print(f\"‚úÖ Tabla creada exitosamente: {PROJECT_CENTRAL}.{DATASET_BRONZE}.consolidated_{table_name}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error creando tabla: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "# üß™ PRUEBA: Crear tabla consolidada para la tabla de prueba\n",
        "if not df_companies.empty:\n",
        "    success = create_consolidated_table(test_table, df_companies)\n",
        "    if success:\n",
        "        print(f\"\\nüéâ ¬°Tabla {test_table} creada exitosamente!\")\n",
        "    else:\n",
        "        print(f\"\\n‚ùå Error creando tabla {test_table}\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  No se puede crear tabla para {test_table} - no hay compa√±√≠as disponibles\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ PASO 4: Validaci√≥n de Tabla Creada\n",
        "\n",
        "Verificamos que la tabla se cre√≥ correctamente y tiene los datos esperados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# üìä VALIDACI√ìN: Informaci√≥n de la Tabla Creada\n",
        "def validate_table(table_name):\n",
        "    \"\"\"Valida que la tabla consolidada se cre√≥ correctamente\"\"\"\n",
        "    \n",
        "    # Informaci√≥n b√°sica de la tabla\n",
        "    query_info = f\"\"\"\n",
        "    SELECT \n",
        "      table_name,\n",
        "      table_type,\n",
        "      row_count,\n",
        "      size_bytes,\n",
        "      creation_time,\n",
        "      last_modified_time\n",
        "    FROM `{PROJECT_CENTRAL}.{DATASET_BRONZE}.INFORMATION_SCHEMA.TABLES`\n",
        "    WHERE table_name = 'consolidated_{table_name}'\n",
        "    \"\"\"\n",
        "    \n",
        "    try:\n",
        "        df_info = client.query(query_info).to_dataframe()\n",
        "        if not df_info.empty:\n",
        "            print(f\"üìä INFORMACI√ìN DE LA TABLA: consolidated_{table_name}\")\n",
        "            print(\"=\" * 80)\n",
        "            print(df_info.to_string(index=False))\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ùå Tabla consolidated_{table_name} no encontrada\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error validando tabla: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "# Validar la tabla de prueba\n",
        "if 'test_table' in locals():\n",
        "    validate_table(test_table)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Ejecuta primero la celda de creaci√≥n de tabla\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# üîç VALIDACI√ìN: Estructura y Datos de la Tabla\n",
        "def show_table_structure(table_name):\n",
        "    \"\"\"Muestra la estructura de la tabla consolidada\"\"\"\n",
        "    \n",
        "    query_columns = f\"\"\"\n",
        "    SELECT \n",
        "      column_name,\n",
        "      ordinal_position,\n",
        "      data_type,\n",
        "      is_nullable\n",
        "    FROM `{PROJECT_CENTRAL}.{DATASET_BRONZE}.INFORMATION_SCHEMA.COLUMNS`\n",
        "    WHERE table_name = 'consolidated_{table_name}'\n",
        "    ORDER BY ordinal_position\n",
        "    \"\"\"\n",
        "    \n",
        "    try:\n",
        "        df_columns = client.query(query_columns).to_dataframe()\n",
        "        if not df_columns.empty:\n",
        "            print(f\"üèóÔ∏è ESTRUCTURA DE LA TABLA: consolidated_{table_name}\")\n",
        "            print(\"=\" * 80)\n",
        "            print(df_columns.to_string(index=False))\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ùå No se encontraron columnas para consolidated_{table_name}\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error obteniendo estructura: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "# Mostrar estructura de la tabla de prueba\n",
        "if 'test_table' in locals():\n",
        "    show_table_structure(test_table)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Ejecuta primero la celda de creaci√≥n de tabla\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# üìà VALIDACI√ìN: Distribuci√≥n por Compa√±√≠a\n",
        "def show_company_distribution(table_name):\n",
        "    \"\"\"Muestra la distribuci√≥n de datos por compa√±√≠a\"\"\"\n",
        "    \n",
        "    # Determinar campo de particionado\n",
        "    if table_name in metadata_dict:\n",
        "        partition_field = metadata_dict[table_name]['partition_fields'][0]\n",
        "    else:\n",
        "        partition_field = 'created_on'\n",
        "    \n",
        "    query_distribution = f\"\"\"\n",
        "    SELECT \n",
        "      company_project_id,\n",
        "      company_id,\n",
        "      COUNT(*) as record_count,\n",
        "      MIN({partition_field}) as earliest_record,\n",
        "      MAX({partition_field}) as latest_record\n",
        "    FROM `{PROJECT_CENTRAL}.{DATASET_BRONZE}.consolidated_{table_name}`\n",
        "    GROUP BY company_project_id, company_id\n",
        "    ORDER BY company_id\n",
        "    \"\"\"\n",
        "    \n",
        "    try:\n",
        "        df_distribution = client.query(query_distribution).to_dataframe()\n",
        "        if not df_distribution.empty:\n",
        "            print(f\"üìà DISTRIBUCI√ìN POR COMPA√ë√çA: consolidated_{table_name}\")\n",
        "            print(\"=\" * 100)\n",
        "            print(df_distribution.to_string(index=False))\n",
        "            \n",
        "            total_records = df_distribution['record_count'].sum()\n",
        "            print(f\"\\nüìä Total de registros: {total_records:,}\")\n",
        "            print(f\"üìä Compa√±√≠as incluidas: {len(df_distribution)}\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ùå No se encontraron datos para consolidated_{table_name}\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error obteniendo distribuci√≥n: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "# Mostrar distribuci√≥n de la tabla de prueba\n",
        "if 'test_table' in locals():\n",
        "    show_company_distribution(test_table)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Ejecuta primero la celda de creaci√≥n de tabla\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ CREAR TODAS LAS TABLAS RESTANTES\n",
        "def create_all_consolidated_tables():\n",
        "    \"\"\"Crea todas las tablas consolidadas disponibles\"\"\"\n",
        "    \n",
        "    if not available_tables:\n",
        "        print(\"‚ùå No hay tablas disponibles. Ejecuta primero el an√°lisis.\")\n",
        "        return\n",
        "    \n",
        "    print(f\"üöÄ CREANDO TODAS LAS TABLAS CONSOLIDADAS\")\n",
        "    print(f\"üìã Total de tablas: {len(available_tables)}\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    success_count = 0\n",
        "    error_count = 0\n",
        "    \n",
        "    for i, table_name in enumerate(available_tables, 1):\n",
        "        print(f\"\\nüìä Procesando {i}/{len(available_tables)}: {table_name}\")\n",
        "        \n",
        "        # Obtener compa√±√≠as para esta tabla\n",
        "        companies_df = get_companies_for_table(table_name)\n",
        "        \n",
        "        if companies_df.empty:\n",
        "            print(f\"  ‚ö†Ô∏è  Sin compa√±√≠as disponibles - SALTAR\")\n",
        "            continue\n",
        "        \n",
        "        # Crear tabla consolidada\n",
        "        success = create_consolidated_table(table_name, companies_df)\n",
        "        \n",
        "        if success:\n",
        "            success_count += 1\n",
        "            print(f\"  ‚úÖ Tabla {table_name} creada exitosamente\")\n",
        "        else:\n",
        "            error_count += 1\n",
        "            print(f\"  ‚ùå Error creando tabla {table_name}\")\n",
        "    \n",
        "    print(f\"\\nüéØ RESUMEN FINAL:\")\n",
        "    print(f\"‚úÖ Tablas creadas exitosamente: {success_count}\")\n",
        "    print(f\"‚ùå Tablas con errores: {error_count}\")\n",
        "    print(f\"üìä Total procesadas: {success_count + error_count}\")\n",
        "\n",
        "# üß™ EJECUTAR CREACI√ìN DE TODAS LAS TABLAS\n",
        "# Descomenta la siguiente l√≠nea para ejecutar todas las tablas:\n",
        "# create_all_consolidated_tables()\n",
        "\n",
        "print(\"üí° Para crear todas las tablas, descomenta la l√≠nea: create_all_consolidated_tables()\")\n",
        "print(\"üìã Tablas disponibles para procesar:\")\n",
        "for table in available_tables:\n",
        "    print(f\"   - {table}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã PASO 6: Verificaci√≥n Final\n",
        "\n",
        "Verificamos que todas las tablas consolidadas se crearon correctamente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# üìä RESUMEN: Todas las Tablas Consolidadas Creadas\n",
        "def show_final_summary():\n",
        "    \"\"\"Muestra el resumen final de todas las tablas consolidadas\"\"\"\n",
        "    \n",
        "    query_summary = f\"\"\"\n",
        "    SELECT \n",
        "      table_name,\n",
        "      table_type,\n",
        "      row_count,\n",
        "      ROUND(size_bytes / 1024 / 1024, 2) as size_mb,\n",
        "      creation_time,\n",
        "      last_modified_time\n",
        "    FROM `{PROJECT_CENTRAL}.{DATASET_BRONZE}.INFORMATION_SCHEMA.TABLES`\n",
        "    WHERE table_name LIKE 'consolidated_%'\n",
        "    ORDER BY row_count DESC\n",
        "    \"\"\"\n",
        "    \n",
        "    try:\n",
        "        df_summary = client.query(query_summary).to_dataframe()\n",
        "        if not df_summary.empty:\n",
        "            print(\"üìä RESUMEN FINAL - TABLAS CONSOLIDADAS CREADAS\")\n",
        "            print(\"=\" * 120)\n",
        "            print(df_summary.to_string(index=False))\n",
        "            \n",
        "            total_tables = len(df_summary)\n",
        "            total_rows = df_summary['row_count'].sum()\n",
        "            total_size = df_summary['size_mb'].sum()\n",
        "            \n",
        "            print(f\"\\nüéØ ESTAD√çSTICAS FINALES:\")\n",
        "            print(f\"üìä Total de tablas consolidadas: {total_tables}\")\n",
        "            print(f\"üìä Total de registros: {total_rows:,}\")\n",
        "            print(f\"üìä Tama√±o total: {total_size:.2f} MB\")\n",
        "            \n",
        "            return True\n",
        "        else:\n",
        "            print(\"‚ùå No se encontraron tablas consolidadas\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error obteniendo resumen: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "# Mostrar resumen final\n",
        "show_final_summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ PR√ìXIMOS PASOS\n",
        "\n",
        "### ‚úÖ Completado:\n",
        "- Tablas consolidadas creadas en `pph-central.bronze`\n",
        "- Optimizadas con particionado y clusterizado\n",
        "- Datos de todas las compa√±√≠as unificados\n",
        "\n",
        "### üîÑ Siguiente Paso:\n",
        "**Crear vistas consolidadas en `pph-central.silver`** que apunten a las tablas bronze creadas.\n",
        "\n",
        "### üìù Notas:\n",
        "- Guarda este notebook como referencia\n",
        "- Puedes reutilizarlo para futuras actualizaciones\n",
        "- Los datos se actualizar√°n cada 6 horas seg√∫n el scheduling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üö® INVESTIGACI√ìN CR√çTICA: ERROR DE NORMALIZACI√ìN EN VISTAS SILVER\n",
        "\n",
        "**PROBLEMA GRAVE:** Las vistas Silver NO est√°n normalizando tipos de datos correctamente.\n",
        "**ERROR:** Column 7 has incompatible types: TIMESTAMP, INT64, TIMESTAMP...\n",
        "\n",
        "**INVESTIGACI√ìN INMEDIATA:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üö® INVESTIGACI√ìN: Comparar Estructuras de Vistas Silver por Compa√±√≠a\n",
        "def investigate_silver_views_structure(table_name):\n",
        "    \"\"\"Investiga las diferencias en estructura de vistas Silver entre compa√±√≠as\"\"\"\n",
        "    \n",
        "    # Obtener compa√±√≠as disponibles\n",
        "    companies_df = get_companies_for_table(table_name)\n",
        "    if companies_df.empty:\n",
        "        print(f\"‚ùå No hay compa√±√≠as para {table_name}\")\n",
        "        return\n",
        "    \n",
        "    print(f\"üîç INVESTIGANDO ESTRUCTURA DE VISTAS SILVER: {table_name}\")\n",
        "    print(\"=\" * 100)\n",
        "    \n",
        "    # Analizar estructura de cada compa√±√≠a\n",
        "    structures = {}\n",
        "    \n",
        "    for _, company in companies_df.iterrows():\n",
        "        project_id = company['company_project_id']\n",
        "        company_name = company['company_name']\n",
        "        \n",
        "        try:\n",
        "            # Query para obtener estructura de la vista Silver\n",
        "            query_structure = f\"\"\"\n",
        "            SELECT \n",
        "              column_name,\n",
        "              ordinal_position,\n",
        "              data_type,\n",
        "              is_nullable\n",
        "            FROM `{project_id}.{DATASET_SILVER}.INFORMATION_SCHEMA.COLUMNS`\n",
        "            WHERE table_name = 'vw_{table_name}'\n",
        "            ORDER BY ordinal_position\n",
        "            \"\"\"\n",
        "            \n",
        "            df_structure = client.query(query_structure).to_dataframe()\n",
        "            \n",
        "            if not df_structure.empty:\n",
        "                structures[company_name] = df_structure\n",
        "                print(f\"‚úÖ {company_name}: {len(df_structure)} columnas\")\n",
        "            else:\n",
        "                print(f\"‚ùå {company_name}: Vista no encontrada\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå {company_name}: Error - {str(e)}\")\n",
        "    \n",
        "    return structures\n",
        "\n",
        "# Investigar appointment (tabla que fall√≥)\n",
        "print(\"üö® INVESTIGACI√ìN CR√çTICA - TABLA: appointment\")\n",
        "structures = investigate_silver_views_structure('appointment')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üö® AN√ÅLISIS: Identificar Columnas con Tipos Incompatibles\n",
        "def find_type_conflicts(structures):\n",
        "    \"\"\"Identifica columnas con tipos de datos incompatibles entre compa√±√≠as\"\"\"\n",
        "    \n",
        "    if not structures:\n",
        "        print(\"‚ùå No hay estructuras para analizar\")\n",
        "        return\n",
        "    \n",
        "    print(\"\\nüîç AN√ÅLISIS DE CONFLICTOS DE TIPOS:\")\n",
        "    print(\"=\" * 100)\n",
        "    \n",
        "    # Obtener todas las columnas √∫nicas\n",
        "    all_columns = set()\n",
        "    for company, df in structures.items():\n",
        "        all_columns.update(df['column_name'].tolist())\n",
        "    \n",
        "    # Analizar cada columna\n",
        "    conflicts = []\n",
        "    \n",
        "    for column in sorted(all_columns):\n",
        "        column_types = {}\n",
        "        \n",
        "        for company, df in structures.items():\n",
        "            col_data = df[df['column_name'] == column]\n",
        "            if not col_data.empty:\n",
        "                data_type = col_data.iloc[0]['data_type']\n",
        "                column_types[company] = data_type\n",
        "        \n",
        "        # Verificar si hay conflictos\n",
        "        unique_types = set(column_types.values())\n",
        "        if len(unique_types) > 1:\n",
        "            conflicts.append({\n",
        "                'column': column,\n",
        "                'types': unique_types,\n",
        "                'companies': column_types\n",
        "            })\n",
        "    \n",
        "    if conflicts:\n",
        "        print(f\"‚ùå CONFLICTOS ENCONTRADOS: {len(conflicts)} columnas\")\n",
        "        print(\"\\nüö® COLUMNAS CON TIPOS INCOMPATIBLES:\")\n",
        "        \n",
        "        for i, conflict in enumerate(conflicts, 1):\n",
        "            print(f\"\\n{i}. COLUMNA: {conflict['column']}\")\n",
        "            print(f\"   TIPOS: {', '.join(conflict['types'])}\")\n",
        "            print(\"   POR COMPA√ë√çA:\")\n",
        "            for company, data_type in conflict['companies'].items():\n",
        "                print(f\"     - {company}: {data_type}\")\n",
        "    else:\n",
        "        print(\"‚úÖ NO HAY CONFLICTOS DE TIPOS\")\n",
        "    \n",
        "    return conflicts\n",
        "\n",
        "# Analizar conflictos en appointment\n",
        "if structures:\n",
        "    conflicts = find_type_conflicts(structures)\n",
        "else:\n",
        "    print(\"‚ùå No hay estructuras para analizar\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üö® SOLUCI√ìN INMEDIATA: Forzar Normalizaci√≥n en Bronze\n",
        "def create_consolidated_table_with_normalization(table_name, companies_df):\n",
        "    \"\"\"Crea tabla consolidada FORZANDO normalizaci√≥n de tipos en bronze\"\"\"\n",
        "    \n",
        "    if companies_df.empty:\n",
        "        print(f\"‚ùå No hay compa√±√≠as disponibles para {table_name}\")\n",
        "        return False\n",
        "    \n",
        "    # Obtener metadatos\n",
        "    if table_name in metadata_dict:\n",
        "        metadata = metadata_dict[table_name]\n",
        "        partition_field = metadata['partition_fields'][0]\n",
        "        cluster_fields = metadata['cluster_fields']\n",
        "    else:\n",
        "        partition_field = 'created_on'\n",
        "        cluster_fields = ['company_id']\n",
        "    \n",
        "    print(f\"üö® SOLUCI√ìN DE EMERGENCIA: Normalizaci√≥n forzada en bronze\")\n",
        "    print(f\"üîÑ Creando tabla consolidada: consolidated_{table_name}\")\n",
        "    print(f\"üìä Compa√±√≠as: {len(companies_df)}\")\n",
        "    \n",
        "    # Construir UNION ALL con normalizaci√≥n forzada\n",
        "    union_parts = []\n",
        "    \n",
        "    for _, company in companies_df.iterrows():\n",
        "        # Aplicar normalizaci√≥n agresiva en el SELECT\n",
        "        union_part = f\"\"\"\n",
        "        SELECT \n",
        "          '{company['company_project_id']}' AS company_project_id,\n",
        "          {company['company_id']} AS company_id,\n",
        "          SAFE_CAST(id AS STRING) AS id,\n",
        "          SAFE_CAST(appointment_type_id AS STRING) AS appointment_type_id,\n",
        "          SAFE_CAST(technician_id AS STRING) AS technician_id,\n",
        "          SAFE_CAST(job_id AS STRING) AS job_id,\n",
        "          SAFE_CAST(customer_id AS STRING) AS customer_id,\n",
        "          SAFE_CAST(created_on AS TIMESTAMP) AS created_on,\n",
        "          SAFE_CAST(updated_on AS TIMESTAMP) AS updated_on,\n",
        "          SAFE_CAST(start_time AS TIMESTAMP) AS start_time,\n",
        "          SAFE_CAST(end_time AS TIMESTAMP) AS end_time,\n",
        "          SAFE_CAST(status AS STRING) AS status,\n",
        "          SAFE_CAST(notes AS STRING) AS notes,\n",
        "          SAFE_CAST(address AS STRING) AS address,\n",
        "          SAFE_CAST(city AS STRING) AS city,\n",
        "          SAFE_CAST(state AS STRING) AS state,\n",
        "          SAFE_CAST(zip AS STRING) AS zip,\n",
        "          SAFE_CAST(phone AS STRING) AS phone,\n",
        "          SAFE_CAST(email AS STRING) AS email,\n",
        "          SAFE_CAST(confirmed AS BOOLEAN) AS confirmed,\n",
        "          SAFE_CAST(completed AS BOOLEAN) AS completed,\n",
        "          SAFE_CAST(cancelled AS BOOLEAN) AS cancelled,\n",
        "          SAFE_CAST(no_show AS BOOLEAN) AS no_show,\n",
        "          SAFE_CAST(rescheduled AS BOOLEAN) AS rescheduled,\n",
        "          SAFE_CAST(arrival_window_start AS TIMESTAMP) AS arrival_window_start,\n",
        "          SAFE_CAST(arrival_window_end AS TIMESTAMP) AS arrival_window_end\n",
        "        FROM `{company['company_project_id']}.{DATASET_SILVER}.vw_{table_name}`\"\"\"\n",
        "        union_parts.append(union_part)\n",
        "    \n",
        "    # Configurar clusterizado\n",
        "    cluster_sql = f\"CLUSTER BY {', '.join(cluster_fields)}\" if cluster_fields else \"\"\n",
        "    \n",
        "    # SQL completo con normalizaci√≥n forzada\n",
        "    create_sql = f\"\"\"\n",
        "    CREATE OR REPLACE TABLE `{PROJECT_CENTRAL}.{DATASET_BRONZE}.consolidated_{table_name}`\n",
        "    PARTITION BY DATE({partition_field})\n",
        "    {cluster_sql}\n",
        "    AS\n",
        "    {' UNION ALL '.join(union_parts)}\n",
        "    \"\"\"\n",
        "    \n",
        "    try:\n",
        "        print(\"üîÑ Ejecutando creaci√≥n con normalizaci√≥n forzada...\")\n",
        "        query_job = client.query(create_sql)\n",
        "        query_job.result()\n",
        "        print(f\"‚úÖ Tabla creada exitosamente: {PROJECT_CENTRAL}.{DATASET_BRONZE}.consolidated_{table_name}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error creando tabla: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "# üö® PRUEBA DE SOLUCI√ìN DE EMERGENCIA\n",
        "print(\"üö® APLICANDO SOLUCI√ìN DE EMERGENCIA PARA appointment\")\n",
        "if not df_companies.empty:\n",
        "    success = create_consolidated_table_with_normalization('appointment', df_companies)\n",
        "    if success:\n",
        "        print(\"üéâ ¬°SOLUCI√ìN APLICADA EXITOSAMENTE!\")\n",
        "    else:\n",
        "        print(\"‚ùå Error aplicando soluci√≥n de emergencia\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No hay compa√±√≠as disponibles para prueba\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
